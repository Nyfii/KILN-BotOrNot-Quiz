window.BOT_OR_NOT_DATA = [
    {
        "media": [
            "Mathias_FAKE_Bundestag.jpeg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Der deutsche Bundestag sieht so nicht aus.",
        "label": "Media"
    },
    {
        "media": [
            "Mathias_FAKE_ZelenskyPutin.jpeg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Der deutsche Bundestag sieht so nicht aus.",
        "label": "Media"
    },
    {
        "media": [
            "Mathias_FAKE_Company.jpeg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Dieses Bild weist untypische Details auf, die auf KI-Generierung hindeuten.",
        "label": "Media"
    },
    {
        "media": [
            "Mathias_FAKE_GroundZero.jpeg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Auffällige Abweichungen im Detail sprechen dafür, dass es sich um ein KI-generiertes Bild handelt.",
        "label": "Media"
    },
    {
        "media": [
            "Mathias_FAKE_Skyscraper.jpeg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Proportionen und Strukturen deuten darauf hin, dass es nicht echt ist.",
        "label": "Media"
    },
    {
        "media": [
            "Mathias_FAKE_UAsoldier.jpeg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Uniformdetails und Gesichtszüge wirken unnatürlich und lassen auf KI schließen.",
        "label": "Media"
    },
    {
        "media": [
            "Mathias_FAKE_Vorlesung.jpeg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Bestimmte Bildmerkmale sind inkonsistent und deuten auf KI-Generierung hin.",
        "label": "Media"
    },
    {
        "media": [
            "Mathias_FAKE_Werkstatt.jpeg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Die Details wirken untypisch für reale Aufnahmen und deuten auf KI hin.",
        "label": "Media"
    },
    {
        "media": [
            "Mathias_FAKE_Wiesn.jpg"
        ],
        "question": "Ist das Bild KI-generiert oder echt?",
        "answers": [
            "Das Bild ist KI-generiert",
            "Das Bild ist echt"
        ],
        "explanation": "Auf dem Freefall-Turm ist das Löwenbräu-Maskottchen zu sehen.",
        "label": "Media"
    },
    {
        "question": "Wer gilt als „Vater der Künstlichen Intelligenz“?",
        "answers": [
            "John McCarthy",
            "Alan Turing",
            "Marvin Minsky",
            "Geoffrey Hinton"
        ],
        "explanation": "John McCarthy prägte 1956 den Begriff „Artificial Intelligence“ und gilt daher als Vater der KI.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Welcher Teilbereich gehört NICHT zur KI?",
        "answers": [
            "Thermodynamik",
            "Maschinelles Lernen",
            "Computer Vision",
            "Natural Language Processing"
        ],
        "explanation": "Thermodynamik ist eine physikalische Disziplin, keine Teildisziplin der KI.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Welche Methode bildet die Grundlage von Deep Learning?",
        "answers": [
            "Künstliche neuronale Netze",
            "Entscheidungsbäume",
            "Lineare Regression",
            "Genetische Algorithmen"
        ],
        "explanation": "Deep Learning basiert auf tiefen künstlichen neuronalen Netzen mit vielen Schichten.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Was versteht man unter „Supervised Learning“?",
        "answers": [
            "Lernen anhand von gelabelten Daten",
            "Lernen ohne jegliche Daten",
            "Lernen durch Ausprobieren ohne Feedback",
            "Lernen durch evolutionäre Prozesse"
        ],
        "explanation": "Beim überwachten Lernen (Supervised Learning) trainiert man ein Modell mit Eingaben und den dazugehörigen richtigen Ausgaben.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Was ist ein bekanntes Beispiel für Reinforcement Learning?",
        "answers": [
            "AlphaGo von DeepMind",
            "Excel Tabellenkalkulation",
            "Siri Sprachassistent",
            "Google Translate"
        ],
        "explanation": "AlphaGo nutzte Reinforcement Learning, um den weltbesten Go-Spieler zu besiegen.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Welche Herausforderung bezeichnet man als „Bias“ in KI-Systemen?",
        "answers": [
            "Verzerrungen durch fehlerhafte oder unausgewogene Trainingsdaten",
            "Höhere Rechenleistung durch GPUs",
            "Geringere Genauigkeit bei großen Datensätzen",
            "Automatische Anpassung der Parameter"
        ],
        "explanation": "Bias entsteht, wenn Daten oder Algorithmen systematisch verzerrte Ergebnisse liefern.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Was beschreibt der Begriff „Turing-Test“?",
        "answers": [
            "Einen Test, ob eine Maschine menschenähnliche Intelligenz vortäuschen kann",
            "Einen Test zur Rechenleistung von Computern",
            "Einen Test zur Genauigkeit von KI-Bilderkennung",
            "Einen Test zur Sicherheit von Netzwerken"
        ],
        "explanation": "Der Turing-Test prüft, ob ein Mensch in einer Kommunikation nicht unterscheiden kann, ob er mit einer KI oder einer Person spricht.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Welcher dieser Bereiche ist ein ethisches Problem bei KI?",
        "answers": [
            "Diskriminierung durch Algorithmen",
            "Geringere Stromkosten",
            "Bessere Bilderkennung",
            "Schnellere Suchmaschinen"
        ],
        "explanation": "Diskriminierung durch KI-Systeme ist ein zentrales ethisches Problem, das stark diskutiert wird.",
        "label": "Ethik"
    },
    {
        "question": "Welche bekannte KI kann menschenähnliche Texte verfassen?",
        "answers": [
            "ChatGPT",
            "Excel",
            "Photoshop",
            "Linux"
        ],
        "explanation": "ChatGPT ist ein KI-Modell für natürliche Sprache und kann menschenähnliche Texte schreiben.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Was versteht man unter „Explainable AI“ (XAI)?",
        "answers": [
            "KI-Systeme, deren Entscheidungen für Menschen nachvollziehbar erklärt werden können",
            "KI, die besonders schnell trainiert werden kann",
            "KI, die automatisch neue Algorithmen generiert",
            "KI, die nur in einfacher Sprache kommuniziert"
        ],
        "explanation": "Explainable AI beschäftigt sich mit der Transparenz und Nachvollziehbarkeit von KI-Entscheidungen.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Welches Risiko besteht bei der Nutzung von Gesichtserkennungssystemen?",
        "answers": [
            "Verletzung der Privatsphäre und Massenüberwachung",
            "Höhere Bildqualität bei Kameras",
            "Schnellere Ladezeiten von Webseiten",
            "Genauere Wettervorhersagen"
        ],
        "explanation": "Gesichtserkennung kann zu Überwachung, Missbrauch und Verlust von Privatsphäre führen.",
        "label": "Ethik"
    },
    {
        "question": "Was bezeichnet man als „Algorithmic Bias“?",
        "answers": [
            "Diskriminierende Ergebnisse aufgrund von verzerrten Daten oder Algorithmen",
            "Eine Methode, um Algorithmen schneller zu machen",
            "Den Ausfall eines Systems durch Überlastung",
            "Ein neutraler Zufallsfehler im Programmcode"
        ],
        "explanation": "Algorithmic Bias beschreibt, dass KI diskriminierende oder verzerrte Ergebnisse liefert, weil die Trainingsdaten Vorurteile enthalten.",
        "label": "Grundwissen KI"
    },
    {
        "question": "Warum sind Deepfakes ein ethisches Problem?",
        "answers": [
            "Sie können Menschen täuschend echt Dinge sagen oder tun lassen, die sie nie gemacht haben",
            "Sie erhöhen die Qualität von Filmen",
            "Sie verbessern medizinische Bilddiagnostik",
            "Sie helfen bei der Kompression von Daten"
        ],
        "explanation": "Deepfakes können zur Manipulation, Verleumdung oder gezielten Desinformation genutzt werden.",
        "label": "Ethik"
    },
    {
        "question": "Welche Gefahr besteht, wenn KI im Arbeitsmarkt eingesetzt wird?",
        "answers": [
            "Automatisierung kann Arbeitsplätze ersetzen und Ungleichheiten verstärken",
            "KI verbessert nur die Ergonomie am Arbeitsplatz",
            "KI reduziert den Stromverbrauch von Computern",
            "KI steigert ausschließlich die Produktivität ohne Risiken"
        ],
        "explanation": "KI kann ganze Berufsfelder automatisieren und soziale sowie ökonomische Ungleichheiten verschärfen.",
        "label": "Ethik"
    },
    {
        "question": "Warum ist Transparenz in KI-Systemen wichtig?",
        "answers": [
            "Damit Entscheidungen nachvollziehbar und überprüfbar sind",
            "Damit Algorithmen schneller laufen",
            "Damit weniger Speicherplatz benötigt wird",
            "Damit KI-Systeme günstiger werden"
        ],
        "explanation": "Transparenz ermöglicht es, Bias, Diskriminierung und Fehlentscheidungen aufzudecken.",
        "label": "Ethik"
    },
    {
        "question": "Welches ethische Problem entsteht bei autonomen Waffensystemen?",
        "answers": [
            "Entscheidungen über Leben und Tod werden von Maschinen getroffen",
            "Sie verbrauchen mehr Strom als herkömmliche Waffen",
            "Sie können keine Ziele mehr erkennen",
            "Sie funktionieren nur bei Sonnenschein"
        ],
        "explanation": "Autonome Waffensysteme werfen fundamentale Fragen nach menschlicher Verantwortung und ethischer Vertretbarkeit auf.",
        "label": "Ethik"
    },
    {
        "question": "Warum ist Datensammlung durch KI ein ethisches Problem?",
        "answers": [
            "Sie kann zu Überwachung und Missbrauch persönlicher Informationen führen",
            "Sie beschleunigt Internetverbindungen",
            "Sie verbessert die Akkulaufzeit von Smartphones",
            "Sie reduziert die Serverkosten"
        ],
        "explanation": "KI-Systeme, die große Mengen an persönlichen Daten sammeln, bergen Risiken für Datenschutz und individuelle Freiheit.",
        "label": "Ethik"
    },
    {
        "question": "Was bedeutet der Begriff \"Künstliche Intelligenz\" allgemein?",
        "answers": [
            "Maschinen, die menschenähnliche Aufgaben lösen",
            "Programme, die nur offline laufen",
            "Roboter mit Armen und Beinen",
            "Systeme, die nur schneller rechnen als andere Computer"
        ],
        "explanation": "KI im engeren Sinn meint Systeme, die Denk- oder Lernaufgaben übernehmen. Offline-Betrieb oder Rechengeschwindigkeit sind keine Definition von Intelligenz. Ein Roboterkörper bedeutet ebenfalls nicht automatisch KI.",
        "label": "Grundlagen"
    },
    {
        "question": "Welche Beschreibung passt am besten zu KI?",
        "answers": [
            "Ein System, das lernen und handeln kann",
            "Ein schneller Computer mit vielen Kernen",
            "Ein Gerät zum Speichern von Daten",
            "Eine Software, die nur programmierten Befehlen folgt"
        ],
        "explanation": "KI ist durch Wahrnehmen, Lernen und Handeln gekennzeichnet. Rechenstärke oder Datenspeicherung allein sind keine Intelligenz. Auch klassische Programme, die nur Anweisungen abarbeiten, gelten nicht als KI.",
        "label": "Grundlagen"
    },
    {
        "question": "Wofür nutzt man in der KI eine Entscheidungsfunktion?",
        "answers": [
            "Um Eingaben in Entscheidungen zu übersetzen",
            "Um Speicherplatz effizienter zu nutzen",
            "Um die Benutzeroberfläche zu verschönern",
            "Um die Geschwindigkeit eines Programms zu erhöhen"
        ],
        "explanation": "Entscheidungsfunktionen ordnen Eingaben Kategorien oder Ergebnissen zu. Speicherplatz, Design oder Geschwindigkeit betreffen technische Aspekte, nicht die Entscheidungslogik.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Welches Beispiel zeigt eine Entscheidungsfunktion?",
        "answers": [
            "Ein Filter, der Spam von E-Mails trennt",
            "Ein Programm, das den Bildschirmhintergrund ändert",
            "Eine Liste aller Internetseiten",
            "Eine Anwendung, die Ordner alphabetisch sortiert"
        ],
        "explanation": "Spamfilter basieren auf Klassifizierung durch Entscheidungsfunktionen. Hintergrund ändern, Listen oder Sortierung sind keine Entscheidungen im KI-Sinn, sondern einfache Programmfunktionen.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Was bedeutet \"Training\" bei einer KI in einfachen Worten?",
        "answers": [
            "Die KI lernt aus Daten oder Feedback, um bessere Entscheidungen zu treffen",
            "Die KI geht zur Schule mit menschlichen Lehrern",
            "Die KI verbessert automatisch ihre Hardware",
            "Die KI kopiert Antworten direkt aus dem Internet"
        ],
        "explanation": "Training heißt, dass die KI ihre Parameter durch viele Beispiele anpasst. Zur Schule gehen ist eine menschliche Metapher. Hardware-Verbesserung hat mit Training nichts zu tun. Antworten aus dem Internet zu kopieren ist kein Lernprozess, sondern nur Abrufen.",
        "label": "Grundlagen"
    },
    {
        "question": "Warum nutzt ein KI-Agent ein Optimierungsverfahren?",
        "answers": [
            "Um Handlungen zu finden, die zu höheren Belohnungen führen",
            "Um den Bildschirm heller zu machen",
            "Um Dateien schneller zu speichern",
            "Um weniger Internet zu verbrauchen"
        ],
        "explanation": "Optimierung bedeutet, die bestmögliche Abfolge von Handlungen zu finden. Bildschirmhelligkeit oder Dateispeicherung sind rein technische Aufgaben. Internetverbrauch hängt nicht mit Entscheidungslogik zusammen.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Welches Optimierungsverfahren ist von der Evolution inspiriert und nutzt Mutation und Selektion?",
        "answers": [
            "Genetische Algorithmen",
            "Dateisortierung",
            "Simulated Annealing",
            "Gradientenabstieg"
        ],
        "explanation": "Genetische Algorithmen imitieren Prinzipien der Evolution. Dateisortierung ist nur eine Programmfunktion. Simulated Annealing orientiert sich an physikalischen Prozessen. Gradientenabstieg ist zwar verbreitet, aber nicht evolutionsinspiriert.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Welcher Ansatz ist die Grundlage für das Training moderner neuronaler Netze?",
        "answers": [
            "Gradientengestütztes Lernen",
            "Münzwurf",
            "Manuelle Regeln",
            "Surfen im Internet"
        ],
        "explanation": "Moderne Netze werden mit Gradientenverfahren trainiert. Münzwurf wäre reiner Zufall. Manuelle Regeln sind Expertensysteme, keine Lernverfahren. Web-Browsing ist keine Lernstrategie.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Was ist die Grundidee einer \"Greedy-Strategie\"?",
        "answers": [
            "Immer die Handlung mit der größten unmittelbaren Belohnung wählen",
            "Immer jedes Risiko vermeiden",
            "Immer das Verhalten von Menschen kopieren",
            "Immer auf die Zukunft warten"
        ],
        "explanation": "Eine Greedy-Strategie nimmt sofort den besten Schritt, auch wenn er später blockiert. Risiko vermeiden ist eine andere Strategie. Menschliches Kopieren ist kein systematisches Verfahren. Auf die Zukunft zu warten bringt keine Entscheidung.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Was bedeutet \"Exploration\" in der KI?",
        "answers": [
            "Neues Verhalten ausprobieren, um mehr zu lernen",
            "Eine neue Webseite besuchen",
            "Nach einem Schatz suchen",
            "Den Computer neu starten"
        ],
        "explanation": "Exploration heißt, die KI probiert aktiv Neues aus, um Informationen über ihre Umgebung zu gewinnen. Webseitenbesuch oder Schatzsuche sind Metaphern, haben aber nichts mit KI zu tun. Neustarten ist ein technischer Vorgang, kein Lernen.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Was zeigt die Angabe \"87% Katze, 11% Hund, 2% Fisch\"?",
        "answers": [
            "Die KI schätzt Wahrscheinlichkeiten statt absoluter Wahrheiten",
            "Die KI hat zu viele Tiere gesehen",
            "Die KI rät ohne Sinn und Logik",
            "Die KI nimmt immer die höchste Zahl und ignoriert dabei alle weiteren Möglichkeiten"
        ],
        "explanation": "Solche Angaben sind Wahrscheinlichkeiten. \"Zu viele Tiere\" oder \"raten\" sind menschliche Bilder. Nur die höchste Zahl zu nehmen beschreibt nicht das eigentliche Vorgehen der KI.",
        "label": "Grundlagen"
    },
    {
        "question": "Was bedeutet \"Confidence\" bei einer KI?",
        "answers": [
            "Wie sicher die KI ihre Antwort darstellt, nicht ob sie stimmt",
            "Dass sie immer die Wahrheit kennt",
            "Dass sie alle Antworten zusätzlich von Menschen gegenprüfen lässt",
            "Dass sie echte Gefühle und Emotionen in die Antworten einbringt"
        ],
        "explanation": "Confidence bezieht sich nur auf die innere Sicherheit des Modells. Absolute Wahrheit oder menschliches Gegenprüfen gehören nicht zum System. Gefühle sind bei KIs nicht vorhanden.",
        "label": "Grundlagen"
    },
    {
        "question": "Was ist der Unterschied zwischen einem Programm und einer KI?",
        "answers": [
            "Programme liefern immer die gleiche Ausgabe, KI kann variieren",
            "Programme sind generell viel langsamer und weniger leistungsfähig als KI-Systeme",
            "KI braucht immer Internet, um zu funktionieren",
            "KI macht keine Fehler und liefert stets die richtige Antwort"
        ],
        "explanation": "Klassische Programme sind deterministisch, während KI probabilistisch arbeitet. Geschwindigkeit ist keine verlässliche Unterscheidung. Internet ist nicht zwingend nötig. Fehlerfreiheit gibt es in keiner Technologie.",
        "label": "Grundlagen"
    },
    {
        "question": "Wovon sind neuronale Netze inspiriert?",
        "answers": [
            "Vom menschlichen Gehirn, nur viel einfacher",
            "Vom Sonnensystem mit seinen Planetenbahnen",
            "Von Kabelnetzen, die Informationen transportieren",
            "Von DNA-Mutationen, die evolutionäre Vielfalt erklären sollen"
        ],
        "explanation": "Neuronale Netze sind stark vereinfachte Modelle, die sich am Gehirn orientieren. Sonnensystem und Kabel sind reine Analogien. DNA-Mutationen gehören zur Biologie, nicht zur Netzarchitektur.",
        "label": "Grundlagen"
    },
    {
        "question": "Warum können KI-Antworten manchmal täuschen?",
        "answers": [
            "Weil die KI ihre Unsicherheit oft nicht anzeigt",
            "Weil die KI zu viele Daten gleichzeitig speichert",
            "Weil die KI grundsätzlich alle Informationen gleich behandelt",
            "Weil die KI langsamer rechnet als ein normaler Computer"
        ],
        "explanation": "KI wirkt oft sehr selbstsicher, auch wenn sie nur Wahrscheinlichkeiten schätzt – deshalb ist das fehlende Anzeigen von Unsicherheit problematisch. Zu viele Daten speichern hat keinen direkten Bezug. \"Alle Informationen gleich behandeln\" beschreibt kein KI-Problem. Rechengeschwindigkeit beeinflusst die Glaubwürdigkeit nicht.",
        "label": "Grundlagen"
    },
    {
        "question": "Was ist das \"Black-Box-Problem\" bei neuronalen Netzen?",
        "answers": [
            "Wir wissen oft nicht genau, warum das Netz eine bestimmte Entscheidung trifft",
            "Das Netz verliert ständig seine gespeicherten Daten",
            "Der Computer schaltet sich unerwartet aus",
            "Die KI versteckt absichtlich ihre Antworten vor den Menschen"
        ],
        "explanation": "Das Black-Box-Problem beschreibt, dass Entscheidungswege in komplexen Netzen schwer nachvollziehbar sind. Datenverlust oder plötzliche Abstürze sind technische Probleme, aber kein Kennzeichen neuronaler Netze. Auch absichtliches Verstecken von Antworten ist kein technischer Fakt.",
        "label": "Grundlagen"
    },
    {
        "question": "Was bedeutet \"Overfitting\" in der KI?",
        "answers": [
            "Das Netz lernt die Trainingsdaten zu gut und scheitert bei neuen Daten",
            "Das Netz läuft aus dem Speicher",
            "Der Computer wird zu heiß beim Rechnen",
            "Die KI gibt ihre Antworten zu schnell aus"
        ],
        "explanation": "Overfitting heißt, dass ein Modell Muster auswendig lernt, ohne sie zu verallgemeinern. Speicherknappheit oder Hitze betreffen Hardware. Schnelligkeit der Ausgabe hat mit Overfitting nichts zu tun.",
        "label": "Grundlagen"
    },
    {
        "question": "Was ist der Hauptzweck eines neuronalen Netzes?",
        "answers": [
            "Muster in Daten zu erkennen und Vorhersagen zu treffen",
            "Große Dateien dauerhaft speichern",
            "Programme schneller laufen lassen",
            "Computer kühlen und Strom sparen"
        ],
        "explanation": "Neuronale Netze sind Werkzeuge zur Mustererkennung und Vorhersage. Speichern, Beschleunigen oder Kühlen sind Hardwareaufgaben, keine Lernziele.",
        "label": "Grundlagen"
    },
    {
        "question": "Was ist \"Artificial Narrow Intelligence (ANI)\"?",
        "answers": [
            "KI, die auf eine bestimmte Aufgabe spezialisiert ist",
            "KI, die alles kann, was Menschen können",
            "KI, die den Menschen in jeder Hinsicht übertrifft",
            "KI, die ohne jedes Training sofort funktioniert"
        ],
        "explanation": "ANI ist eine spezialisierte KI für einzelne Aufgaben. Allgemeine Intelligenz oder Superintelligenz gehören in andere Kategorien. Ohne Training sofortige Leistung ist unrealistisch.",
        "label": "Grundlagen"
    },
    {
        "question": "Welches ist ein Beispiel für \"Narrow AI\"?",
        "answers": [
            "Ein Programm, das Schach extrem gut spielt",
            "Ein Roboter, der jede menschliche Fähigkeit lernt",
            "Eine Maschine, die klüger ist als alle Menschen",
            "Ein selbstbewusster Assistent mit eigenen Gefühlen"
        ],
        "explanation": "Schach-KIs sind typische Beispiele für Narrow AI. Roboter mit allen Fähigkeiten, Supermaschinen oder selbstbewusste Assistenten gehören nicht zu dieser Kategorie.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Was bedeutet \"Artificial General Intelligence (AGI)\"?",
        "answers": [
            "Eine hypothetische KI, die Probleme so flexibel lösen könnte wie Menschen",
            "Ein Schachcomputer",
            "Ein Spamfilter",
            "Ein Roboter-Staubsauger"
        ],
        "explanation": "AGI bezeichnet eine noch nicht existierende, menschenähnliche Intelligenz. Schachcomputer, Spamfilter oder Haushaltsroboter sind spezialisierte Systeme, keine AGI.",
        "label": "Grundlagen"
    },
    {
        "question": "Was ist \"Artificial Super Intelligence (ASI)\"?",
        "answers": [
            "Eine theoretische KI, die den Menschen in allen Bereichen übertrifft",
            "Ein Programm, das einfach schneller läuft als andere",
            "Eine KI, die niemals Fehler macht",
            "Ein Roboter mit echten menschlichen Gefühlen"
        ],
        "explanation": "ASI ist ein theoretisches Konzept einer übermenschlichen Intelligenz. Schnelligkeit oder Fehlerfreiheit allein machen keine Superintelligenz aus. Auch echte Emotionen sind nicht zwingend Teil einer solchen KI.",
        "label": "Grundlagen"
    },
    {
        "question": "Was braucht die KI beim überwachten Lernen?",
        "answers": [
            "Trainingsdaten mit Labels (richtigen Antworten)",
            "Unbegrenzten Speicherplatz",
            "Menschliche Gefühle",
            "Eine ständige Internetverbindung"
        ],
        "explanation": "Beim überwachten Lernen wird die KI mit Beispielen gefüttert, bei denen die richtige Lösung schon bekannt ist. Speicherplatz allein ersetzt keine Labels. Gefühle sind irrelevant. Eine Internetverbindung ist nicht nötig, wenn die Daten lokal vorliegen.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Welche Aufgabe passt zum überwachten Lernen?",
        "answers": [
            "Erkennen, ob eine E-Mail Spam ist oder nicht",
            "Muster in Daten ohne Labels finden",
            "Ein Auto im Straßenverkehr steuern",
            "Musik völlig neu aus dem Nichts erzeugen"
        ],
        "explanation": "Spamfilter nutzen überwachte Klassifikatoren. Muster ohne Labels gehören zum unüberwachten Lernen. Autonomes Fahren ist eine komplexe Mischung verschiedener Methoden. Musik generieren fällt eher unter generative Modelle.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Wie funktioniert unüberwachtes Lernen?",
        "answers": [
            "Es sucht Muster in Daten ohne Labels",
            "Es kopiert immer nur menschliche Eingaben",
            "Es lernt nur aus Belohnungen oder Strafen",
            "Es löscht unnötige Daten automatisch"
        ],
        "explanation": "Unüberwachtes Lernen erkennt Strukturen in nicht beschrifteten Daten. Reines Kopieren wäre kein Lernen. Belohnungen und Strafen gehören ins Verstärkungslernen. Daten löschen ist ein technischer Vorgang, kein Lernprinzip.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Welche Lernmethode nutzt Belohnung und Bestrafung?",
        "answers": [
            "Verstärkungslernen",
            "Überwachtes Lernen mit vorbereiteten Labels",
            "Unüberwachtes Lernen mit reinen Mustern",
            "Zufälliges Raten ohne jede Grundlage"
        ],
        "explanation": "Beim Reinforcement Learning passt die KI ihr Verhalten durch Feedback über Belohnungen oder Strafen an. Labels sind nur im überwachten Lernen wichtig. Mustererkennung ohne Feedback ist unüberwacht. Zufall ohne Feedback wäre kein systematisches Lernen.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Was bedeutet halbüberwachtes Lernen?",
        "answers": [
            "Eine kleine Menge gelabelter Daten zusammen mit vielen ungelabelten Daten nutzen",
            "Lernen nur mit Belohnung und Strafe ohne Beispiele",
            "Lernen ausschließlich mit vollständigen Labels",
            "Ganz ohne Daten trainieren"
        ],
        "explanation": "Semi-supervised kombiniert teure, aufwendig gelabelte Daten mit vielen unbeschrifteten Beispielen. Nur Belohnung und Strafe gehört zum Reinforcement Learning. Nur Labels = klassisches überwachte Lernen. Ohne Daten kann keine KI lernen.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Worum geht es bei \"Natural Language Processing\" (NLP)?",
        "answers": [
            "Um das Verstehen und Erzeugen menschlicher Sprache",
            "Um das Erkennen von Gesichtern in Bildern",
            "Um die Steuerung physischer Roboter im Alltag",
            "Um das Spielen von Brettspielen durch Algorithmen"
        ],
        "explanation": "NLP befasst sich mit natürlicher Sprache, Text und Spracheingaben. Gesichtserkennung gehört zur Computer Vision. Robotersteuerung ist Robotik. Brettspiele fallen oft unter Planung und Reinforcement Learning.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Wofür wird \"Computer Vision\" eingesetzt?",
        "answers": [
            "Zur Interpretation von Bildern und Videos",
            "Zum Führen von Gesprächen in natürlicher Sprache",
            "Zum Nachbilden menschlicher Gehirnfunktionen",
            "Zum automatischen Schreiben von Programmcode"
        ],
        "explanation": "Computer Vision ist für Bild- und Videoanalyse zuständig. Gespräche gehören zu NLP. Gehirn-Simulation fällt in die Neurowissenschaft. Codegenerierung ist eine generative KI-Aufgabe.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Was bedeutet \"Multi-Modal AI\"?",
        "answers": [
            "Eine KI, die mit verschiedenen Datenarten arbeiten kann (z. B. Text, Bilder und Audio)",
            "Eine KI, die nur offline funktioniert",
            "Eine KI mit mehreren Persönlichkeiten gleichzeitig",
            "Eine KI, die mehrere Computer benötigt, um zu starten"
        ],
        "explanation": "Multi-Modal AI verarbeitet unterschiedliche Eingabemodalitäten wie Text, Bild und Ton. Offline-Nutzung, Persönlichkeiten oder mehrere Computer sind keine fachliche Definition.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Was ist der Hauptunterschied zwischen AGI und GPAI?",
        "answers": [
            "AGI ist ein Forschungskonzept, GPAI eine rechtliche Definition",
            "AGI funktioniert immer, GPAI nicht",
            "GPAI bedeutet, dass die KI Gefühle hat",
            "AGI bezieht sich ausschließlich auf Roboterkörper"
        ],
        "explanation": "AGI (Artificial General Intelligence) ist ein theoretisches Ziel, GPAI ein juristischer Begriff im EU AI Act. „Gefühle“ und „Roboterkörper“ sind Missverständnisse. „Funktioniert immer“ ist Unsinn.",
        "label": "Grundlagen"
    },
    {
        "question": "Was sagt der EU AI Act über GPAI-Modelle?",
        "answers": [
            "Sie unterliegen besonderen Regeln zur Sicherheit und Missbrauchsprävention",
            "Sie müssen immer quelloffen sein, egal wer sie entwickelt",
            "Sie müssen menschenähnlich aussehen, um zugelassen zu werden",
            "Sie dürfen keine Bilder oder Texte erzeugen"
        ],
        "explanation": "GPAI-Modelle haben im EU-Recht zusätzliche Auflagen zur Transparenz und Sicherheit. Open Source ist nicht verpflichtend, menschenähnliches Aussehen ist irrelevant, und generative Fähigkeiten sind erlaubt.",
        "label": "Recht und Gesellschaft"
    },
    {
        "question": "Welches dieser Systeme ist ein Beispiel für ein GPAI-Modell nach dem EU AI Act?",
        "answers": [
            "GPT-4",
            "Ein Taschenrechner",
            "Ein Schachcomputer",
            "Eine Waschmaschine"
        ],
        "explanation": "GPT-4 erfüllt die Definition von GPAI durch seine Vielseitigkeit. Ein Taschenrechner und Schachcomputer sind spezialisierte Systeme. Waschmaschinen sind gar keine KI.",
        "label": "Recht und Gesellschaft"
    },
    {
        "question": "Warum können Artikel über AGI und GPAI verwirrend sein?",
        "answers": [
            "Weil die Begriffe vor dem EU AI Act oft synonym verwendet wurden",
            "Weil KI ihre eigenen Definitionen ständig ändert",
            "Weil nur Wissenschaftler diese Begriffe benutzen dürfen",
            "Weil Computer keine Zeitungen lesen können"
        ],
        "explanation": "Vor der rechtlichen Festlegung wurden AGI und GPAI oft durcheinander genutzt. KI definiert sich nicht selbst, Begriffe sind frei verwendbar, und Zeitungslesen ist für die Begriffsverwendung irrelevant.",
        "label": "Grundlagen"
    },
    {
        "question": "Warum können nur wenige Firmen die größten KI-Modelle trainieren?",
        "answers": [
            "Weil das Training enorme Rechenleistung und spezialisierte Rechenzentren benötigt",
            "Weil kleine Firmen generell keine KI mögen",
            "Weil KI ausschließlich im Weltraum trainiert werden muss",
            "Weil Heimcomputer zu schnell wären und die Modelle zerstören könnten"
        ],
        "explanation": "Das Training benötigt riesige Datenmengen und Hardware, die sich nur große Firmen leisten können. Abneigung, Weltraumtraining oder „zu schnelle PCs“ sind Unsinn.",
        "label": "Recht und Gesellschaft"
    },
    {
        "question": "Was ist der Unterschied zwischen Training und Inferenz bei KI?",
        "answers": [
            "Training bedeutet Lernen aus Daten (sehr rechenintensiv), Inferenz ist das Anwenden zur Beantwortung (weniger aufwendig)",
            "Training macht die KI größer, Inferenz macht sie kleiner",
            "Training wird von Menschen durchgeführt, Inferenz nur von Robotern",
            "Es gibt überhaupt keinen Unterschied"
        ],
        "explanation": "Training passt die Parameter des Modells an, während Inferenz die Nutzung des Modells ist. Größenänderungen sind kein Lernprozess. Mensch/Roboter-Trennung ist falsch. „Kein Unterschied“ ist schlicht inkorrekt.",
        "label": "Grundlagen"
    },
    {
        "question": "Welche Art von KI-System ist nach dem EU AI Act komplett verboten?",
        "answers": [
            "Social-Scoring-Systeme",
            "Spamfilter",
            "Chatbots",
            "Medizinische Diagnosewerkzeuge"
        ],
        "explanation": "Social Scoring gilt als inakzeptables Risiko und ist in der EU verboten. Spamfilter und Chatbots sind erlaubt, aber reguliert. Medizinische Diagnose ist Hochrisiko, aber nicht verboten.",
        "label": "Recht und Gesellschaft"
    },
    {
        "question": "Welche Kategorie von KI gilt als \"hohes Risiko\"?",
        "answers": [
            "Systeme in Bereichen wie Medizin oder Justiz",
            "Spiele und Unterhaltung",
            "Spamfilter",
            "Online-Empfehlungen beim Einkauf"
        ],
        "explanation": "Hochrisiko betrifft Systeme, die gravierende Folgen für Menschen haben, etwa in Justiz oder Gesundheit. Unterhaltung, Spamfilter oder Online-Shops haben ein geringeres Risiko.",
        "label": "Recht und Gesellschaft"
    },
    {
        "question": "Was ist für \"begrenztes Risiko\"-Systeme wie Chatbots vorgeschrieben?",
        "answers": [
            "Transparenzpflichten",
            "Überhaupt keine Regeln",
            "Direkte Kontrolle durch den Staat",
            "Nur offline nutzbar"
        ],
        "explanation": "Systeme mit begrenztem Risiko müssen ihre KI-Nutzung klar machen. „Keine Regeln“ stimmt nicht, ebenso wenig eine Zwangskontrolle. Offline-Nutzung ist keine gesetzliche Vorgabe.",
        "label": "Recht und Gesellschaft"
    },
    {
        "question": "Wozu dient eine \"Sandbox\" in der KI-Entwicklung?",
        "answers": [
            "Um KI in einer sicheren, isolierten Umgebung zu testen",
            "Um Internetverbindungen schneller zu machen",
            "Um die KI kreativer wirken zu lassen",
            "Um den Stromverbrauch direkt zu senken"
        ],
        "explanation": "Eine Sandbox erlaubt gefahrloses Testen vor dem Einsatz. Internetgeschwindigkeit, Kreativität oder Energieverbrauch sind nicht das Ziel.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Was wollen \"Bias-Checks\" in KI-Systemen verhindern?",
        "answers": [
            "Diskriminierung und ungerechte Ergebnisse",
            "Lange Antwortzeiten",
            "Zu viele Nutzerfragen",
            "Übermäßige Datenspeicherung"
        ],
        "explanation": "Bias-Checks sollen Vorurteile und Diskriminierung verhindern. Antwortzeiten oder viele Nutzerfragen sind Performance-Themen. Datenspeicherung betrifft eher Datenschutz.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Was war das erste von Asimovs drei Robotergesetzen?",
        "answers": [
            "Ein Roboter darf keinem Menschen schaden oder durch Untätigkeit Schaden zulassen",
            "Ein Roboter muss immer die Wahrheit sagen",
            "Ein Roboter darf niemals Strom benutzen",
            "Ein Roboter darf seine Fabrik nicht verlassen"
        ],
        "explanation": "Das erste Gesetz schützt Menschen vor Schaden. Wahrheitspflicht, Stromnutzung oder Fabrikgebot kommen in Asimovs Gesetzen nicht vor.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Warum sind Asimovs drei Gesetze für reale KI nicht praktisch?",
        "answers": [
            "Weil Begriffe wie \"Schaden\" für Maschinen zu ungenau sind",
            "Weil Roboter sich generell weigern, Regeln zu befolgen",
            "Weil Gesetze nur für Menschen gelten dürfen",
            "Weil Computer keine Literatur kennen"
        ],
        "explanation": "Maschinen können vage Begriffe nicht eindeutig interpretieren. Roboter „weigern“ sich nicht, sondern folgen Programmen. Gesetze können durchaus auch Technik regulieren. Literaturkenntnis ist irrelevant.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Was ist ein \"System Prompt\"?",
        "answers": [
            "Eine versteckte Anweisung, die das Standardverhalten der KI festlegt",
            "Eine Liste von Quellen für die Antwort",
            "Die Berufsbezeichnung des Nutzers",
            "Ein rechtlicher Haftungshinweis"
        ],
        "explanation": "System Prompts steuern das Grundverhalten im Hintergrund. Quellenlisten, Jobtitel oder Disclaimer sind keine System Prompts.",
        "label": "Grundlagen"
    },
    {
        "question": "Was bewirkt eine Erhöhung der \"Temperatur\"?",
        "answers": [
            "Antworten werden vielfältiger und kreativer, aber weniger konsistent",
            "Die KI bekommt mehr Emotionen",
            "Die Hardware läuft schneller",
            "Die Antworten sind garantiert korrekt"
        ],
        "explanation": "Temperatur steuert die Variabilität der Textgenerierung. Emotionen sind ein Missverständnis. Hardwaregeschwindigkeit ist unabhängig. Korrektheit ist nie garantiert.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Was beschreibt das \"Context Window\"?",
        "answers": [
            "Die maximale Textmenge, die ein Modell gleichzeitig berücksichtigen kann",
            "Die Anzahl der Nutzer in einem Chat",
            "Die Größe der Internetverbindung",
            "Die Menge an Bildern, die gespeichert werden kann"
        ],
        "explanation": "Das Context Window begrenzt, wie viel Text die KI \"im Blick\" haben kann. Nutzerzahl, Verbindung oder Bildspeicherung haben nichts damit zu tun.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Was bedeutet \"Fine-Tuning\"?",
        "answers": [
            "Weiteres Training eines Modells mit neuen Beispielen zur Spezialisierung",
            "Die App neu starten",
            "Längere Prompts in den Chat schreiben",
            "Das Datenset komprimieren, um Speicherplatz zu sparen"
        ],
        "explanation": "Fine-Tuning bedeutet, ein bestehendes Modell gezielt mit neuen Daten nachzutrainieren. Neustart oder längere Eingaben verändern das Modell nicht. Datenset-Komprimierung spart nur Speicher, verbessert aber nicht die Spezialisierung.",
        "label": "Lernen und Entscheidungsfindung"
    },
    {
        "question": "Warum werden beim Training separate Validierungsdaten genutzt?",
        "answers": [
            "Um zu prüfen, ob das Modell auch bei unbekannten Daten funktioniert",
            "Um das Training schneller zu machen",
            "Um die Größe des Datensatzes zu erhöhen",
            "Um den Stromverbrauch während des Trainings zu senken"
        ],
        "explanation": "Validierungsdaten prüfen die Fähigkeit zur Generalisierung. Geschwindigkeit, Datensatzgröße oder Stromverbrauch hängen nicht vom Validierungsset ab.",
        "label": "Grundlagen"
    },
    {
        "question": "Warum haben viele kommerzielle KI-Systeme Inhaltsfilter?",
        "answers": [
            "Um schädliche oder illegale Inhalte zu blockieren und Gesetze einzuhalten",
            "Um Antworten kürzer zu machen",
            "Um die Berechnungen der KI zu beschleunigen",
            "Um weniger Speicher im System zu verbrauchen"
        ],
        "explanation": "Filter sollen Nutzer schützen und rechtliche Vorgaben einhalten. Kürze, Geschwindigkeit oder Speicher sind nicht der Hauptzweck.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Welche Kategorie blockieren Filter typischerweise?",
        "answers": [
            "Anleitungen zu illegalem Verhalten",
            "Filmempfehlungen aus Streaming-Plattformen",
            "Wettervorhersagen für verschiedene Regionen",
            "Ergebnisse von Sportereignissen"
        ],
        "explanation": "Filter greifen vor allem bei Gewalt, illegalem Verhalten oder Hassrede. Filmempfehlungen, Wetter oder Sport sind unproblematische Inhalte.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Was ist ein zentrales Problem bei keyword-basierten Filtern?",
        "answers": [
            "Sie können harmlose Diskussionen blockieren oder leicht umgangen werden",
            "Sie finden garantiert jede gefährliche Nachricht",
            "Sie machen das Lernen des Modells automatisch schneller",
            "Sie übersetzen Inhalte zuverlässig in andere Sprachen"
        ],
        "explanation": "Keyword-Filter sind ungenau und leicht zu umgehen. Sie garantieren keine Vollständigkeit. Modelltraining beschleunigen oder Übersetzung leisten sie nicht.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Warum kann Filterung politisch riskant sein?",
        "answers": [
            "Modelle aus manchen Ländern können gezielt für Propaganda angepasst werden",
            "Filter verbessern automatisch die Demokratie",
            "Filter entfernen ausschließlich Spam-Nachrichten",
            "Filter machen Modelle kreativer in ihren Antworten"
        ],
        "explanation": "Filter können von Regierungen oder Anbietern für politische Zwecke missbraucht werden. Demokratie stärken, Spam oder Kreativität sind keine Hauptprobleme.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Was ist eine Gefahr, wenn eine KI sehr schwache oder keine Filter hat?",
        "answers": [
            "Sie kann bei Aufforderung gewaltvolle oder hasserfüllte Inhalte erzeugen",
            "Sie läuft viel langsamer als andere Modelle",
            "Sie beantwortet grundsätzlich keine Fragen",
            "Sie weigert sich, lokal auf einem Computer zu starten"
        ],
        "explanation": "Fehlende Filter erhöhen das Risiko gefährlicher Inhalte. Langsamkeit, Verweigerung oder Startprobleme sind keine typischen Folgen.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Wie können Modelle für Propaganda missbraucht werden?",
        "answers": [
            "Indem man sie so trainiert oder feinabstimmt, dass sie bestimmte politische Ansichten bevorzugen",
            "Indem man sie dazu bringt, alte Daten zu vergessen",
            "Indem man nur die Temperatureinstellung erhöht",
            "Indem man ihr Kontextfenster stark reduziert"
        ],
        "explanation": "Durch gezieltes Training können Modelle politische Tendenzen verstärken. Daten löschen, Temperatur oder Kontextfenster betreffen nur Technik und beeinflussen keine politische Ausrichtung.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Was bedeutet \"Halluzination\" in der KI?",
        "answers": [
            "Die KI erzeugt Inhalte, die wie Fakten klingen, aber falsch sind",
            "Die KI wird plötzlich selbstbewusst",
            "Die KI verweigert jede Antwort",
            "Die KI zeigt anstelle von Text nur Bilder"
        ],
        "explanation": "Halluzinationen sind falsche, aber überzeugend formulierte Antworten. Selbstbewusstsein, Antwortverweigerung oder Bilderausgabe haben damit nichts zu tun.",
        "label": "Grundlagen"
    },
    {
        "question": "Warum ist der Einsatz von KI in Berufen wie Ärzten oder Therapeuten problematisch?",
        "answers": [
            "Weil Menschen der KI auch dann zu stark vertrauen könnten, wenn sie Fehler macht",
            "Weil KI immer alle Fragen verweigert",
            "Weil KI nicht auf modernen Computern läuft",
            "Weil KI niemals Rechtschreibfehler macht"
        ],
        "explanation": "Übermäßiges Vertrauen ist riskant, besonders in sensiblen Bereichen. Verweigerung, technische Inkompatibilität oder perfekte Rechtschreibung sind keine realen Kernprobleme.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Welche Art von Sprache ist für KI besonders schwer zu verstehen?",
        "answers": [
            "Ironie, Sarkasmus und kulturelle Anspielungen",
            "Zahlen und Datumsangaben",
            "Einfache Begrüßungen",
            "Wetterberichte"
        ],
        "explanation": "Ironie und kulturelle Kontexte sind schwer, da sie implizites Wissen erfordern. Zahlen, Begrüßungen oder Wetter sind meist leicht zu verarbeiten.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Warum werden traditionelle Algorithmen manchmal einer KI vorgezogen?",
        "answers": [
            "Weil sie transparent und vorhersehbar sind",
            "Weil sie grundsätzlich schneller arbeiten",
            "Weil sie keinen Strom verbrauchen",
            "Weil sie ganz ohne Daten auskommen"
        ],
        "explanation": "Klassische Algorithmen sind nachvollziehbar und stabil. Geschwindigkeit, Stromfreiheit oder Datenlosigkeit sind falsche Annahmen.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Was ist eine wichtige Einschränkung von KI beim Erkennen von Inhalten?",
        "answers": [
            "Sie kann einschätzen, ob etwas generiert oder manipulativ wirkt, aber nicht, ob es faktisch wahr ist",
            "Sie lehnt grundsätzlich jeden Text ab",
            "Sie kann nur sehr kurze Sätze überprüfen",
            "Sie zeigt niemals ihre Antworten an"
        ],
        "explanation": "KI kann Wahrscheinlichkeiten und Muster prüfen, aber nicht objektive Wahrheit feststellen. Alles ablehnen oder nie anzeigen wäre praxisfern. Nur kurze Sätze sind keine echte Einschränkung.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Welches Merkmal kann auf ein KI-generiertes Bild hinweisen?",
        "answers": [
            "Ungewöhnliche Hände oder verzerrter Text",
            "Auffällig helle Farben",
            "Kleine Dateigröße",
            "Landschaften im Hintergrund"
        ],
        "explanation": "Hände und Schrift sind klassische Schwachpunkte vieler Bildmodelle. Farben, Dateigröße oder Landschaften sind kein verlässlicher Hinweis.",
        "label": "Anwendungen und Fähigkeiten"
    },
    {
        "question": "Was bedeutet das \"Alignment-Problem\" in der KI?",
        "answers": [
            "Das Risiko, dass eine mächtige KI Ziele verfolgt, die nicht mit menschlichen Werten übereinstimmen",
            "Die Schwierigkeit, Hardware richtig zu verbinden",
            "Das Problem, KI-Antworten kürzer zu machen",
            "Das Ausrichten von Text in einem Dokument"
        ],
        "explanation": "Alignment betrifft die Übereinstimmung von KI-Zielen mit menschlichen Interessen. Hardware, Textlänge oder Dokumentformatierung haben damit nichts zu tun.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Warum vermuten einige Forscher, dass KI bald ein Plateau erreicht?",
        "answers": [
            "Weil hochwertige Trainingsdaten im Internet knapp werden",
            "Weil Computer bald nicht mehr funktionieren",
            "Weil Menschen das Interesse an KI verlieren",
            "Weil das Internet zu langsam geworden ist"
        ],
        "explanation": "Das Plateau bezieht sich auf Datenqualität als limitierenden Faktor. Defekte Computer, fehlendes Interesse oder Internetgeschwindigkeit sind keine Kernprobleme.",
        "label": "Grundlagen"
    },
    {
        "question": "Was bedeutet \"Point of No Return\" in KI-Debatten?",
        "answers": [
            "Die Vorstellung, dass sich eine selbstverbessernde KI irgendwann nicht mehr von Menschen stoppen lässt",
            "Der Moment, in dem KI eine Frage nicht beantwortet",
            "Ein Zeitpunkt im Training, an dem Daten gelöscht werden",
            "Eine Situation, in der das Internet ausfällt"
        ],
        "explanation": "Der Begriff beschreibt eine hypothetische Schwelle unkontrollierbarer Selbstverbesserung. Antwortverweigerung, Datenlöschung oder Internetausfall sind etwas ganz anderes.",
        "label": "Risiken und Ethik"
    },
    {
        "question": "Welches dieser Bilder ist echt?",
        "media": [
            "Nyfii_REAL_3DPrinter.jpg",
            "Nyfii_FAKE_3DPrinter.jpg"
        ],
        "explanation": "Die Rolle im Fake Bild \"schwebt\" in der Halterung.",
        "label": "Bild-Erkennung"
    },
    {
        "question": "Ist dieses Bild echt?",
        "media": [
            "Nyfii_FAKE_GroceryShopping.jpg"
        ],
        "answers": [
            "Nein",
            "Ja"
        ],
        "explanation": "Der Eierkarton verschmilzt mit dem Einkaufswagen. Die Haupt hat keine Struktur.",
        "label": "Bild-Erkennung"
    },
    {
        "question": "Ist dieses Bild echt?",
        "media": [
            "Nyfii_FAKE_Car.jpg"
        ],
        "answers": [
            "Nein",
            "Ja"
        ],
        "explanation": "Auf dem Kennzeichen ist bei dem Eurofeld eine 4.",
        "label": "Bild-Erkennung"
    },
    {
        "question": "Welches dieser Bilder ist echt?",
        "media": [
            "Nyfii_REAL_Cat.jpg",
            "Nyfii_FAKE_Cat.jpg"
        ],
        "explanation": "Im Fell der echten Katze sieht mal viel mehr Struktur.",
        "label": "Bild-Erkennung"
    },
    {
        "question": "Welches dieser Bilder ist echt?",
        "media": [
            "Nyfii_REAL_Code.jpg",
            "Nyfii_FAKE_Code.jpg"
        ],
        "explanation": "Der falsche Code ist inkonsistent in den Tags.",
        "label": "Bild-Erkennung"
    },
    {
        "question": "Welches dieser Bilder ist echt?",
        "media": [
            "Nyfii_REAL_Crescione.jpg",
            "Nyfii_FAKE_Crescione.jpg"
        ],
        "explanation": "Der falsche Crescione hat eine unnatürliche Farbe und eine Körnung im Bild.",
        "label": "Bild-Erkennung"
    },
    {
        "question": "Welches dieser Bilder ist echt?",
        "media": [
            "Nyfii_REAL_Cube.jpg",
            "Nyfii_FAKE_Cube.jpg"
        ],
        "explanation": "Der falsche Würfel hat ein Oranges-Oranges Kantenteil, was so nicht möglich ist.",
        "label": "Bild-Erkennung"
    },
    {
        "question": "Welches dieser Bilder ist echt?",
        "media": [
            "Nyfii_REAL_GreenScreen.jpg",
            "Nyfii_FAKE_GreenScreen.jpg"
        ],
        "explanation": "Schatten.",
        "label": "Bild-Erkennung"
    },
    {
        "question": "Ist dieses Bild echt?",
        "media": [
            "Nyfii_FAKE_StreetCrossing.jpg"
        ],
        "answers": [
            "Nein",
            "Ja"
        ],
        "explanation": "Die Verkehrsschilder sind komplett falsch.",
        "label": "Bild-Erkennung."
    },
    {
        "question": "Ist dieses Bild echt?",
        "media": [
            "Nyfii_FAKE_TrainLounge.jpg"
        ],
        "answers": [
            "Nein",
            "Ja"
        ],
        "explanation": "Gesichter.",
        "label": "Bild-Erkennung."
    },
    {
        "question": "Ist dieses Bild echt?",
        "media": [
            "Nyfii_REAL_Monopoly.jpg"
        ],
        "answers": [
            "Ja",
            "Nein"
        ],
        "explanation": ":)",
        "label": "Bild-Erkennung."
    },
    {
        "question": "Ist dieses Bild echt?",
        "media": [
            "Nyfii_REAL_Tower.jpg"
        ],
        "answers": [
            "Ja",
            "Nein"
        ],
        "explanation": ":)",
        "label": "Bild-Erkennung."
    }
]